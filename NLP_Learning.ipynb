{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          body_text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortcut\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection.tsv',sep = '\\t' , header = None)\n",
    "df.columns = ['label','body_text']\n",
    "#df.drop(df[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5568\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5568\n",
      "5568\n"
     ]
    }
   ],
   "source": [
    "# to check if both the columns have same number of rows\n",
    "\n",
    "print(len(df['body_text']))\n",
    "print(len(df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5568, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spams : 746 \n",
      "Hams : 4822\n"
     ]
    }
   ],
   "source": [
    "print(\"Spams : {} \\nHams : {}\".format(len(df[df['label']=='spam']),len(df[df['label']=='ham'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# missing data\n",
    "\n",
    "print(df['label'].isnull().sum())\n",
    "print(df['body_text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though  \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.  \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('Display.max_colwidth',100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                       body_text_clean  \n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...  \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...  \n",
       "2                                          Nah I dont think he goes to usf he lives around here though  \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent  \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "df['body_text_clean'] = df['body_text'].apply(lambda x: remove_punct(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                       body_text_clean  \\\n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "2                                          Nah I dont think he goes to usf he lives around here though   \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                                                                   body_text_tokenized  \n",
       "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...  \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...  \n",
       "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]  \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]  \n",
       "4                                                           [i, have, a, date, on, sunday, with, will]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+',text)\n",
    "    return tokens\n",
    "df['body_text_tokenized']=df['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                       body_text_clean  \\\n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "2                                          Nah I dont think he goes to usf he lives around here though   \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                                                                   body_text_tokenized  \\\n",
       "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
       "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]   \n",
       "4                                                           [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                                                                      body_text_nostop  \n",
       "0  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...  \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...  \n",
       "2                                                 [nah, dont, think, goes, usf, lives, around, though]  \n",
       "3                                              [even, brother, like, speak, treat, like, aids, patent]  \n",
       "4                                                                                       [date, sunday]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(tokenized_list):\n",
    "    text = [word for word in tokenized_list if word not in stopwords]\n",
    "    return text\n",
    "df['body_text_nostop'] = df['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmetizing\n",
    "ws = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_clean</th>\n",
       "      <th>body_text_tokenized</th>\n",
       "      <th>body_text_nostop</th>\n",
       "      <th>body_text_lemmetize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
       "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
       "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
       "      <td>ive searching right word thank breather promise wont take help granted fulfil promise wonderful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
       "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
       "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
       "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
       "      <td>[date, sunday]</td>\n",
       "      <td>date sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1  spam   \n",
       "2   ham   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                             body_text  \\\n",
       "0  I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "3                        Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "\n",
       "                                                                                       body_text_clean  \\\n",
       "0  Ive been searching for the right words to thank you for this breather I promise i wont take your...   \n",
       "1  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...   \n",
       "2                                          Nah I dont think he goes to usf he lives around here though   \n",
       "3                          Even my brother is not like to speak with me They treat me like aids patent   \n",
       "4                                                                    I HAVE A DATE ON SUNDAY WITH WILL   \n",
       "\n",
       "                                                                                   body_text_tokenized  \\\n",
       "0  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...   \n",
       "1  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...   \n",
       "2                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]   \n",
       "3         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]   \n",
       "4                                                           [i, have, a, date, on, sunday, with, will]   \n",
       "\n",
       "                                                                                      body_text_nostop  \\\n",
       "0  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...   \n",
       "1  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...   \n",
       "2                                                 [nah, dont, think, goes, usf, lives, around, though]   \n",
       "3                                              [even, brother, like, speak, treat, like, aids, patent]   \n",
       "4                                                                                       [date, sunday]   \n",
       "\n",
       "                                                                                   body_text_lemmetize  \n",
       "0  ive searching right word thank breather promise wont take help granted fulfil promise wonderful ...  \n",
       "1  free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questions...  \n",
       "2                                                             nah dont think go usf life around though  \n",
       "3                                                        even brother like speak treat like aid patent  \n",
       "4                                                                                          date sunday  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmetizing(tokenized_text):\n",
    "    text = \" \".join([ws.lemmatize(word) for word in tokenized_text])\n",
    "    return text\n",
    "df['body_text_lemmetize'] = df['body_text_nostop'].apply(lambda x: lemmetizing(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>body_text</th>\n",
       "      <th>body_text_lemmetize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
       "      <td>ive searching right word thank breather promise wont take help granted fulfil promise wonderful ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>nah dont think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
       "      <td>even brother like speak treat like aid patent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>date sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy...</td>\n",
       "      <td>2nd time tried 2 contact u u 750 pound prize 2 claim easy call 087187272008 now1 10p per minute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other suggestions?</td>\n",
       "      <td>pity mood soany suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd be interested in buying something else next week ...</td>\n",
       "      <td>guy bitching acted like id interested buying something else next week gave u free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5568 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label  \\\n",
       "0      ham   \n",
       "1     spam   \n",
       "2      ham   \n",
       "3      ham   \n",
       "4      ham   \n",
       "...    ...   \n",
       "5563  spam   \n",
       "5564   ham   \n",
       "5565   ham   \n",
       "5566   ham   \n",
       "5567   ham   \n",
       "\n",
       "                                                                                                body_text  \\\n",
       "0     I've been searching for the right words to thank you for this breather. I promise i wont take yo...   \n",
       "1     Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "2                                           Nah I don't think he goes to usf, he lives around here though   \n",
       "3                           Even my brother is not like to speak with me. They treat me like aids patent.   \n",
       "4                                                                     I HAVE A DATE ON SUNDAY WITH WILL!!   \n",
       "...                                                                                                   ...   \n",
       "5563  This is the 2nd time we have tried 2 contact u. U have won the £750 Pound prize. 2 claim is easy...   \n",
       "5564                                                                 Will ü b going to esplanade fr home?   \n",
       "5565                                            Pity, * was in mood for that. So...any other suggestions?   \n",
       "5566  The guy did some bitching but I acted like i'd be interested in buying something else next week ...   \n",
       "5567                                                                           Rofl. Its true to its name   \n",
       "\n",
       "                                                                                      body_text_lemmetize  \n",
       "0     ive searching right word thank breather promise wont take help granted fulfil promise wonderful ...  \n",
       "1     free entry 2 wkly comp win fa cup final tkts 21st may 2005 text fa 87121 receive entry questions...  \n",
       "2                                                                nah dont think go usf life around though  \n",
       "3                                                           even brother like speak treat like aid patent  \n",
       "4                                                                                             date sunday  \n",
       "...                                                                                                   ...  \n",
       "5563  2nd time tried 2 contact u u 750 pound prize 2 claim easy call 087187272008 now1 10p per minute ...  \n",
       "5564                                                                          ü b going esplanade fr home  \n",
       "5565                                                                           pity mood soany suggestion  \n",
       "5566                    guy bitching acted like id interested buying something else next week gave u free  \n",
       "5567                                                                                       rofl true name  \n",
       "\n",
       "[5568 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.loc[:,('label','body_text','body_text_lemmetize')]\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature_extraction\n",
    "\n",
    "df_clean['body_length'] = df_clean['body_text'].apply(lambda x:len(x) - x.count(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")),3)*100\n",
    "df_clean['punct%'] = df_clean['body_text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature_evaluation\n",
    "\n",
    "bins = np.linspace(0,200,40)\n",
    "pyplot.hist(df_clean[df_clean['label']=='spam']['body_length'], bins, alpha=0.5, density = True, label='spam')\n",
    "pyplot.hist(df_clean[df_clean['label']=='ham']['body_length'], bins, alpha=0.5, density = True, label='ham')\n",
    "pyplot.legend(loc= 'upper left')\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0,50,40)\n",
    "pyplot.hist(df_clean[df_clean['label']=='spam']['punct%'], bins, alpha=0.5, density = True, label='spam')\n",
    "pyplot.hist(df_clean[df_clean['label']=='ham']['punct%'], bins, alpha=0.5, density = True, label='ham')\n",
    "pyplot.legend(loc= 'upper left')\n",
    "pyplot.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_clean[['body_text', 'body_length', 'punct%']], df_clean['label'],test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ws.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_length</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>7878</th>\n",
       "      <th>7879</th>\n",
       "      <th>7880</th>\n",
       "      <th>7881</th>\n",
       "      <th>7882</th>\n",
       "      <th>7883</th>\n",
       "      <th>7884</th>\n",
       "      <th>7885</th>\n",
       "      <th>7886</th>\n",
       "      <th>7887</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.142029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7890 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_length  punct%         0    1    2    3    4    5    6    7  ...  \\\n",
       "0           49     4.1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1           19    10.5  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2          113     7.1  0.142029  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3          199     4.5  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4           33     3.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "   7878  7879  7880  7881  7882  7883  7884  7885  7886  7887  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 7890 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(x_train['body_text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(x_train['body_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(x_test['body_text'])\n",
    "\n",
    "x_train_vect = pd.concat([x_train[['body_length', 'punct%']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "x_test_vect = pd.concat([x_test[['body_length', 'punct%']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "x_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21646972, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7878</th>\n",
       "      <th>7879</th>\n",
       "      <th>7880</th>\n",
       "      <th>7881</th>\n",
       "      <th>7882</th>\n",
       "      <th>7883</th>\n",
       "      <th>7884</th>\n",
       "      <th>7885</th>\n",
       "      <th>7886</th>\n",
       "      <th>7887</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4454 rows × 7888 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9     ...  \\\n",
       "0     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2     0.142029   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "4449  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4450  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4451  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4452  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4453  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "      7878  7879  7880  7881  7882  7883  7884  7885  7886  7887  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "4449   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4450   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4451   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4452   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4453   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[4454 rows x 7888 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rf = RandomForestClassifier()\\nparam = {'n_estimators': [10, 150, 300], \\n         'max_depth': [30, 60, 90, None]}\\n\\ngs = GridSearchCV(rf, param, cv= 5, n_jobs=-1)\\ngs_fit = gs.fit(X_features, df_clean['label'])\\npd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending = False)[0:5]\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300], \n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv= 5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_features, df_clean['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending = False)[0:5]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 8.535 / Predict time: 0.265 ---- Precision: 1.0 / Recall: 0.871 / Accuracy: 0.984\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(x_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred_rf = rf_model.predict(x_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred_rf, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'\n",
    "      .format(round(fit_time, 3), round(pred_time, 3), \n",
    "              round(precision, 3), round(recall, 3), round((y_pred_rf==y_test).sum()/len(y_pred_rf), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"gb = GradientBoostingClassifier()\\nparam2 = {'n_estimators': [100, 150], \\n         'max_depth': [7, 11, 15],\\n         'learning_rate': [0.1]}\\n\\ngs = GridSearchCV(gb, param2, cv= 5, n_jobs=-1)\\ngs_fit = gs.fit(X_features, df_clean['label'])\\npd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending = False)[0:5]\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gb = GradientBoostingClassifier()\n",
    "param2 = {'n_estimators': [100, 150], \n",
    "         'max_depth': [7, 11, 15],\n",
    "         'learning_rate': [0.1]}\n",
    "\n",
    "gs = GridSearchCV(gb, param2, cv= 5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_features, df_clean['label'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score',ascending = False)[0:5]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 233.841 / Predict time: 0.227 ---- Precision: 0.952 / Recall: 0.857 / Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(x_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred_gb = gb_model.predict(x_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred_gb, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'\n",
    "      .format(round(fit_time, 3), round(pred_time, 3), \n",
    "              round(precision, 3), round(recall, 3), round((y_pred_gb==y_test).sum()/len(y_pred_gb), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 0.492 / Predict time: 0.092 ---- Precision: 0.964 / Recall: 0.579 / Accuracy: 0.944\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "\n",
    "start = time.time()\n",
    "MNB_model = MNB.fit(x_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred_MNB = MNB_model.predict(x_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "precision, recall, fscore, train_support = score(y_test, y_pred_MNB, pos_label='spam', average='binary')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'\n",
    "      .format(round(fit_time, 3), round(pred_time, 3), \n",
    "              round(precision, 3), round(recall, 3), round((y_pred_MNB==y_test).sum()/len(y_pred_MNB), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter SMS :Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us\n"
     ]
    }
   ],
   "source": [
    "body_text = [input(\"Enter SMS :\")]\n",
    "body_length = len(body_text[0]) - body_text[0].count(\" \")\n",
    "punct = count_punct(body_text[0])\n",
    "SMS = pd.DataFrame({'body_text':body_text,'body_length':body_length,'punct%':punct})\n",
    "SMS_test = tfidf_vect_fit.transform(SMS['body_text'])\n",
    "SMS_test_vect = pd.concat([SMS[['body_length', 'punct%']].reset_index(drop=True), \n",
    "           pd.DataFrame(SMS_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMS_pred_rf = rf_model.predict(SMS_test_vect)\n",
    "SMS_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMS_pred_gb = gb_model.predict(SMS_test_vect)\n",
    "SMS_pred_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMS_pred_MNB = MNB_model.predict(SMS_test_vect)\n",
    "SMS_pred_MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
